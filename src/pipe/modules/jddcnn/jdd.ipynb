{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint denoising and demosaicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install tensorflow:\n",
    "\n",
    "make pip virtual environment,\n",
    "```\n",
    "python3 -m venv tensorflow\n",
    "cd tensorflow\n",
    "source tensorflow/bin/activate\n",
    "```\n",
    "then install\n",
    "```\n",
    "python3 -m pip install tensorflow[and-cuda]\n",
    "pip install jupyter matplotlib\n",
    "ipython kernel install --user --name=venv\n",
    "jupyter notebook this-notebook.ipynb\n",
    "```\n",
    "and then select the venv kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.python.client import device_lib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import struct\n",
    "\n",
    "rng = np.random.default_rng(666)\n",
    "\n",
    "# Check if the GPU is detected\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "[x.name for x in local_device_protos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TILE_SIZE = 128\n",
    "TILES_PER_IMAGE = 1000\n",
    "NUM_TRAINING_IMG = 7\n",
    "\n",
    "# probably not much more to gain for the training data we currently have\n",
    "EPOCHS_COUNT = 100\n",
    "\n",
    "# this is going to be rggb in planes. 5th channel is noise estimation\n",
    "INPUT_CHANNELS_COUNT = 5\n",
    "\n",
    "MODEL_NAME = str(EPOCHS_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reference_pfm(filename):\n",
    "    decoded = []\n",
    "    with open(filename, 'rb') as pfm_file:\n",
    "\n",
    "        line1, line2, line3 = (pfm_file.readline().decode('latin-1').strip() for _ in range(3))\n",
    "        assert line1 in ('PF', 'Pf')\n",
    "        \n",
    "        channels = 3 if \"PF\" in line1 else 1\n",
    "        width, height = (int(s) for s in line2.split())\n",
    "        scale_endianess = float(line3)\n",
    "        bigendian = scale_endianess > 0\n",
    "        scale = abs(scale_endianess)\n",
    "\n",
    "        buffer = pfm_file.read()\n",
    "        samples = width * height * channels\n",
    "        assert len(buffer) == samples * 4\n",
    "        \n",
    "        fmt = f'{\"<>\"[bigendian]}{samples}f'\n",
    "        decoded = struct.unpack(fmt, buffer)\n",
    "    # make sure extent is multiple of 2\n",
    "    decoded = np.reshape(np.array(decoded), (height, width, 3))\n",
    "    wd = (width//2)*2\n",
    "    ht = (height//2)*2\n",
    "    decoded = decoded[:ht,:wd,:]\n",
    "    image_tensor = tf.constant(decoded, dtype=np.float16)\n",
    "    image_tensor = tf.reshape(image_tensor, [ht, wd, 3])\n",
    "    return image_tensor\n",
    "\n",
    "def display_img(img):\n",
    "    plt.imshow(img.numpy().astype(np.float32)[:,:,:3])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_tiles(img, n, ox, oy, flip, noise_a, noise_b):\n",
    "    res = []\n",
    "    for i in range(n):\n",
    "        # do some augmentation shenannigans: flip, add noise, mosaic, add noise estimation as channel\n",
    "        b = img[oy[i]:oy[i]+TILE_SIZE,ox[i]:ox[i]+TILE_SIZE,:]\n",
    "        if flip[i] == 1:\n",
    "            b = np.flip(b, 0)\n",
    "        if flip[i] == 2:\n",
    "            b = np.flip(b, 1)\n",
    "        if flip[i] == 3:\n",
    "            b = np.flip(b, (0,1))\n",
    "        # cut into mosaic planes\n",
    "        wd = TILE_SIZE\n",
    "        ht = TILE_SIZE\n",
    "        red    = np.reshape(b[0:ht:2,0:wd:2,0], (ht//2,wd//2))\n",
    "        green0 = np.reshape(b[1:ht:2,0:wd:2,1], (ht//2,wd//2))\n",
    "        green1 = np.reshape(b[0:ht:2,1:wd:2,1], (ht//2,wd//2))\n",
    "        blue   = np.reshape(b[1:ht:2,1:wd:2,2], (ht//2,wd//2))\n",
    "        # compute noise channel and simulate additive gaussian/poissonian noise\n",
    "        noise  = np.sqrt(noise_a[i] + noise_b[i] * green0)\n",
    "        red    = red    + np.sqrt(np.maximum(noise_a[i] + red   *noise_b[i], 0.0))*np.reshape(rng.normal(0, 1, (ht//2) * (wd//2)),  (ht//2,wd//2))\n",
    "        green0 = green0 + np.sqrt(np.maximum(noise_a[i] + green0*noise_b[i], 0.0))*np.reshape(rng.normal(0, 1, (ht//2) * (wd//2)),  (ht//2,wd//2))\n",
    "        green1 = green1 + np.sqrt(np.maximum(noise_a[i] + green1*noise_b[i], 0.0))*np.reshape(rng.normal(0, 1, (ht//2) * (wd//2)),  (ht//2,wd//2))\n",
    "        blue   = blue   + np.sqrt(np.maximum(noise_a[i] + blue  *noise_b[i], 0.0))*np.reshape(rng.normal(0, 1, (ht//2) * (wd//2)),  (ht//2,wd//2))\n",
    "        b = np.stack((red,green0,green1,blue,noise),axis=2)\n",
    "        deg = tf.constant(b, dtype=np.float16)\n",
    "        deg = tf.reshape(deg, [ht//2, wd//2, 5])\n",
    "        res.append(deg)\n",
    "    return res\n",
    "\n",
    "def generate_output_tiles(img, n, ox, oy, flip):\n",
    "    return [\n",
    "        img[oy[i]:oy[i]+TILE_SIZE,ox[i]:ox[i]+TILE_SIZE,:] if flip[i] == 0 else\n",
    "        np.flip(img[oy[i]:oy[i]+TILE_SIZE,ox[i]:ox[i]+TILE_SIZE,:], 0 if flip[i] == 1 else (1 if flip[i] == 2 else (0,1)))\n",
    "        for i in range(n)\n",
    "    ]\n",
    "\n",
    "def display_tile_grid(tiles, lines_count=4, columns_count=2, size=2):\n",
    "    fig, axes = plt.subplots(lines_count, columns_count*len(tiles), figsize=(size*columns_count*len(tiles), size*lines_count))\n",
    "\n",
    "    for i in range(lines_count):\n",
    "        for j in range(columns_count):\n",
    "            for k in range(len(tiles)):\n",
    "                ax = axes[i, j*len(tiles) + k]\n",
    "                ax.imshow(tiles[k][i*columns_count + j].numpy().astype(np.float32)[:,:,:3], interpolation='nearest')\n",
    "                ax.axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in range(NUM_TRAINING_IMG):\n",
    "    folder = 'data/img_' + str(i).zfill(4)\n",
    "    img_output = read_reference_pfm(folder + '.pfm')\n",
    "\n",
    "    images.append(img_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(images[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_input = []\n",
    "tiles_expected = []\n",
    "\n",
    "for i in range(NUM_TRAINING_IMG):\n",
    "    \n",
    "    img_expected = images[i]\n",
    "    n = TILES_PER_IMAGE\n",
    "    ox = rng.integers(0, np.shape(img_expected)[1]-TILE_SIZE, n)\n",
    "    oy = rng.integers(0, np.shape(img_expected)[0]-TILE_SIZE, n)\n",
    "    flip = rng.integers(0, 4, n)\n",
    "    # noise_a = rng.uniform(0, 1000.0/65535.0, n)\n",
    "    # noise_b = rng.uniform(0, 20.0/65535.0, n)\n",
    "    noise_a = rng.exponential(100.0/65535.0, n)\n",
    "    noise_b = rng.exponential(2.0/65535.0, n)\n",
    "\n",
    "\n",
    "    tiles_input += generate_input_tiles(img_expected, n, ox, oy, flip, noise_a, noise_b)\n",
    "    tiles_expected += generate_output_tiles(img_expected, n, ox, oy, flip)\n",
    "\n",
    "tiles_input, tiles_expected = tf.convert_to_tensor(tiles_input), tf.convert_to_tensor(tiles_expected)\n",
    "\n",
    "display_tile_grid([tiles_input, tiles_expected], size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "# TODO make sure this does *not* overlap with the training input..\n",
    "validation_tiles_input = tiles_input[-10:]\n",
    "validation_tiles_expected = tiles_expected[-10:]\n",
    "\n",
    "\n",
    "validation_tiles_input, validation_tiles_expected = tf.convert_to_tensor(validation_tiles_input), tf.convert_to_tensor(validation_tiles_expected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (None, None, INPUT_CHANNELS_COUNT)\n",
    "\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "x_128 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "\n",
    "x_64 = layers.MaxPooling2D((2, 2))(x_128)\n",
    "x_64 = layers.Conv2D(43, (3, 3), activation='relu', padding='same')(x_64)\n",
    "\n",
    "x_32 = layers.MaxPooling2D((2, 2))(x_64)\n",
    "x_32 = layers.Conv2D(57, (3, 3), activation='relu', padding='same')(x_32)\n",
    "\n",
    "x_16 = layers.MaxPooling2D((2, 2))(x_32)\n",
    "x_16 = layers.Conv2D(76, (3, 3), activation='relu', padding='same')(x_16)\n",
    "\n",
    "x_8 = layers.MaxPooling2D((2, 2))(x_16)\n",
    "x_8 = layers.Conv2D(101, (3, 3), activation='relu', padding='same')(x_8)\n",
    "\n",
    "x_4 = layers.MaxPooling2D((2, 2))(x_8)\n",
    "x_4 = layers.Conv2D(101, (3, 3), activation='relu', padding='same')(x_4)\n",
    "\n",
    "x = layers.UpSampling2D(size=(2, 2),interpolation='nearest')(x_4)\n",
    "x = layers.Concatenate()([x, x_8]) # Skip connection\n",
    "# x = layers.Conv2D(101, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.Conv2D(101, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "x = layers.UpSampling2D(size=(2, 2),interpolation='nearest')(x)\n",
    "x = layers.Concatenate()([x, x_16]) # Skip connection\n",
    "# x = layers.Conv2D(76, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.Conv2D(76, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "x = layers.UpSampling2D(size=(2, 2),interpolation='nearest')(x)\n",
    "x = layers.Concatenate()([x, x_32]) # Skip connection\n",
    "# x = layers.Conv2D(57, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.Conv2D(57, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "x = layers.UpSampling2D(size=(2, 2),interpolation='nearest')(x)\n",
    "x = layers.Concatenate()([x, x_64]) # Skip connection\n",
    "# x = layers.Conv2D(43, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.Conv2D(43, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "x = layers.UpSampling2D(size=(2, 2),interpolation='nearest')(x)\n",
    "x = layers.Concatenate()([x, x_128]) # Skip connection\n",
    "# x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "# the number of output channels here makes the next layer insanely expensive. can we do with less?\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "x = layers.Concatenate()([x, inputs]) # Skip connection\n",
    "x = layers.UpSampling2D(size=(2, 2),interpolation='nearest')(x)\n",
    "# x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "# XXX why is this float32?\n",
    "x = layers.Conv2D(3, (3, 3), activation='relu', padding='same', dtype='float32')(x)\n",
    "\n",
    "outputs = x\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "hist = model.fit(tiles_input, tiles_expected, epochs=EPOCHS_COUNT, validation_data=(validation_tiles_input, validation_tiles_expected))\n",
    "\n",
    "\n",
    "training_loss = hist.history['loss']\n",
    "validation_loss = hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write raw f16 coefficients of the model into a file.\n",
    "# probably in the future also write some information about training data/loss/network configuration?\n",
    "model.get_weights()\n",
    "with open(MODEL_NAME+'.dat', 'wb') as f:\n",
    "    for a in model.get_weights():\n",
    "        f.write(a.astype('float16').tobytes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = range(10, len(training_loss))\n",
    "plt.plot(xs, training_loss[10:], label = 'Training loss')\n",
    "plt.plot(xs, validation_loss[10:], label = 'Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training data\n",
    "predictions = tf.convert_to_tensor(model.predict(tiles_input))\n",
    "\n",
    "display_tile_grid([tiles_input, predictions, tiles_expected], size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the evaluation data\n",
    "test_predictions = tf.convert_to_tensor(model.predict(validation_tiles_input))\n",
    "\n",
    "display_tile_grid([validation_tiles_input, test_predictions, validation_tiles_expected], lines_count=4, size=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
